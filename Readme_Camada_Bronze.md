# üöÄ Projeto: Ingest√£o de Dados no Data Lakehouse

## üìå Vis√£o Geral

Este projeto tem como objetivo a constru√ß√£o de um **Data Lakehouse** utilizando o **Databricks** e tecnologias associadas, como **Apache Spark**, **Delta Lake** e **Parquet**. O foco principal est√° na ingest√£o, processamento e estrutura√ß√£o de dados de um ambiente de e-commerce, garantindo **alta performance**, **escalabilidade** e **governan√ßa dos dados**.

---

## üéØ Motiva√ß√£o e Problema a Ser Resolvido

Empresas de e-commerce lidam com grandes volumes de dados provenientes de m√∫ltiplas fontes, como transa√ß√µes, cadastros de clientes e dados de produtos.

Entretanto, armazenar e processar esses dados de forma eficiente representa um desafio, especialmente ao se buscar:

‚úÖ Escalabilidade para lidar com altos volumes de dados  
‚úÖ Qualidade e confiabilidade na an√°lise e tomada de decis√£o  
‚úÖ Flexibilidade para consultas anal√≠ticas e aprendizado de m√°quina  
‚úÖ Redu√ß√£o de custos operacionais em rela√ß√£o a arquiteturas tradicionais de Data Warehouses  

---

## üí° Solu√ß√£o Proposta

Para resolver esses desafios, implementamos uma arquitetura **Lakehouse**, unificando:

- A escalabilidade e flexibilidade dos **Data Lakes**
- Com a governan√ßa e estrutura√ß√£o de **Data Warehouses**

### üèóÔ∏è Arquitetura Medallion

Adotamos a **Arquitetura Medallion (Medalh√£o)**, estruturada em tr√™s camadas:

üî∏ **Bronze** ‚Äì Armazena dados brutos sem transforma√ß√£o, garantindo um hist√≥rico completo  
üî∏ **Silver** ‚Äì Processa e enriquece os dados, assegurando qualidade e padroniza√ß√£o  
üî∏ **Gold** ‚Äì Cont√©m dados refinados e agregados, otimizados para an√°lises e relat√≥rios  

Al√©m disso, aplicamos o **modelo Star Schema** na camada Gold, organizando os dados em **tabelas fato** e **dimens√£o**, facilitando consultas anal√≠ticas eficientes.

---

## ü™ô Camada Bronze

A **Camada Bronze** √© respons√°vel por armazenar os dados exatamente como foram recebidos, **sem qualquer transforma√ß√£o**. Essa abordagem assegura:

- Rastreabilidade total
- Possibilidade de reprocessamento futuro
- Preserva√ß√£o da integridade e fidelidade da fonte original

---

## üîß Tecnologias Utilizadas

- **Apache Spark**  
- **Delta Lake**  
- **Databricks**  
- **Parquet**  
- **Azure Data Lake Storage (Gen2)**  
- **Star Schema Modeling**

---




# üß† Guia Explicativo: Boas Pr√°ticas na Camada Bronze

Este documento re√∫ne as boas pr√°ticas aplicadas na **Camada Bronze** do pipeline de dados, com foco em performance, economia de recursos e confiabilidade.

---

## üî∑ Camada Bronze (Ingest√£o)

### ‚úÖ Respons√°vel por:
- Capturar dados brutos de m√∫ltiplas fontes (CSV, APIs, arquivos externos).
- Armazenar em Delta Lake mantendo fidelidade com a fonte.

### ‚úÖ Melhorias aplicadas:

- üì• **Auto Loader com `trigger(once)`** para leitura eficiente e econ√¥mica.
- üßπ Pr√©-tratamento b√°sico: `dropDuplicates`, `na.drop()`.
- üìÅ Particionamento por data (`partitionBy("data_carga")`).
- üíæ Salvamento em formato Delta Lake com schema evolution.

---

## 1. ‚úÖ Leitura eficiente com Auto Loader

### ‚ùå Antes (forma tradicional):
```python
spark.read.format("csv").load("caminho/dados")
```
Essa abordagem:
- L√™ todos os arquivos de uma vez, toda vez;
- N√£o escala bem para grandes volumes;
- N√£o detecta automaticamente novos arquivos (sem reprocessar os antigos).

### ‚úÖ Agora (com Auto Loader):
```python
spark.readStream \
     .format("cloudFiles") \
     .option("cloudFiles.format", "csv") \
     .load(BRONZE_PATH)
```

### üìå Vantagens:
- Detecta automaticamente arquivos novos (sem reler os antigos);
- Ideal para pipelines cont√≠nuos ou agendados;
- Melhor uso de recursos do cluster;
- Suporta grandes volumes com performance.

---

## 2. ‚úÖ Particionamento correto dos dados

### Exemplo:
```python
.write.partitionBy("data_carga")
```

### üß† O que √© `partitionBy`?
√â uma forma de **organizar fisicamente os arquivos no Data Lake**. Por exemplo:
```
bronze/clientes/data_carga=2025-04-14/
bronze/clientes/data_carga=2025-04-15/
```

### üìå Vantagens:
- Spark l√™ apenas o necess√°rio (ex: apenas um m√™s);
- Reduz tempo de leitura e custo computacional;
- Evita leitura desnecess√°ria (√≥timo em grandes volumes).

---

## 3. ‚úÖ Trigger otimizada para controle de recursos

### Exemplo:
```python
.writeStream \
     .trigger(once=True)
```

### üß† Por que isso √© importante?
Spark Structured Streaming normalmente fica monitorando o tempo todo. Isso **consome o cluster**, mesmo sem novos arquivos.

### üìå Com `.trigger(once=True)`:
- Executa apenas uma vez e finaliza o job;
- Ideal para **pipelines batch automatizados**;
- Evita consumo desnecess√°rio de recursos.

---

## 4. ‚úÖ Uso de checkpoint e schema evolution

### Exemplo:
```python
.option("checkpointLocation", checkpoint_path) \
.option("mergeSchema", "true")
```

### üß† Para que serve?
- `checkpointLocation`: salva o **estado atual** da leitura cont√≠nua;
- `mergeSchema`: permite aceitar **novas colunas** sem quebrar o pipeline.

### üìå Vantagens:
- Garante **toler√¢ncia a falhas**;
- Permite **evolu√ß√£o segura** do schema;
- Pipeline mais resiliente em produ√ß√£o.

---

## 5. ‚úÖ Limpeza e tratamento antecipado

### Exemplo:
```python
df = df.dropDuplicates().na.drop()
```

### üß† Explica√ß√£o:
- `dropDuplicates()`: remove registros duplicados;
- `na.drop()`: remove linhas com valores nulos (null).

### üìå Por que fazer isso na Bronze?
- Reduz complexidade nas camadas Silver e Gold;
- Evita erros em joins e m√©tricas erradas;
- Garante que os dados cheguem limpos para an√°lise.

---

## ‚úÖ Resumo Visual

| T√©cnica                       | Benef√≠cio principal                         |
|-------------------------------|----------------------------------------------|
| Auto Loader                   | Leitura escal√°vel e incremental              |
| partitionBy                   | Leitura seletiva, performance e economia     |
| trigger(once=True)            | Controle de execu√ß√£o e uso do cluster        |
| checkpoint + mergeSchema      | Toler√¢ncia a falhas e schema flex√≠vel        |
| dropDuplicates + na.drop()    | Dados limpos desde a origem                  |

---

> _"Engenharia de dados come√ßa na Bronze: quanto melhor a base, mais poderosa ser√° a entrega."_

