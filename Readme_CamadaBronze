ğŸ§  Guia Explicativo: Boas PrÃ¡ticas na Camada Bronze

Este documento reÃºne as boas prÃ¡ticas aplicadas na Camada Bronze do pipeline de dados, com foco em performance, economia de recursos e confiabilidade.


1. âœ… Leitura eficiente com Auto Loader

âŒ Antes (forma tradicional):

spark.read.format("csv").load("caminho/dados")

Essa abordagem:

LÃª todos os arquivos de uma vez, toda vez;

NÃ£o escala bem para grandes volumes;

NÃ£o detecta automaticamente novos arquivos (sem reprocessar os antigos).

âœ… Agora (com Auto Loader):

spark.readStream \
     .format("cloudFiles") \
     .option("cloudFiles.format", "csv") \
     .load(BRONZE_PATH)

ğŸ“Œ Vantagens:

Detecta automaticamente arquivos novos (sem reler os antigos);

Ideal para pipelines contÃ­nuos ou agendados;

Melhor uso de recursos do cluster;

Suporta grandes volumes com performance.



2. âœ… Particionamento correto dos dados

Exemplo:

.write.partitionBy("data_carga")

ğŸ§  O que Ã© partitionBy?

Ã‰ uma forma de organizar fisicamente os arquivos no Data Lake. Por exemplo:

bronze/clientes/data_carga=2025-04-14/
bronze/clientes/data_carga=2025-04-15/

ğŸ“Œ Vantagens:

Spark lÃª apenas o necessÃ¡rio (ex: apenas um mÃªs);

Reduz tempo de leitura e custo computacional;

Evita leitura desnecessÃ¡ria (Ã³timo em grandes volumes).



3. âœ… Trigger otimizada para controle de recursos

Exemplo:

.writeStream \
     .trigger(once=True)

ğŸ§  Por que isso Ã© importante?

Spark Structured Streaming normalmente fica monitorando o tempo todo. Isso consome o cluster, mesmo sem novos arquivos.

ğŸ“Œ Com .trigger(once=True):

Executa apenas uma vez e finaliza o job;

Ideal para pipelines batch automatizados;

Evita consumo desnecessÃ¡rio de recursos.



4. âœ… Uso de checkpoint e schema evolution

Exemplo:

.option("checkpointLocation", checkpoint_path) \
.option("mergeSchema", "true")

ğŸ§  Para que serve?

checkpointLocation: salva o estado atual da leitura contÃ­nua;

mergeSchema: permite aceitar novas colunas sem quebrar o pipeline.

ğŸ“Œ Vantagens:

Garante tolerÃ¢ncia a falhas;

Permite evoluÃ§Ã£o segura do schema;

Pipeline mais resiliente em produÃ§Ã£o.



5. âœ… Limpeza e tratamento antecipado

Exemplo:

df = df.dropDuplicates().na.drop()

ğŸ§  ExplicaÃ§Ã£o:

dropDuplicates(): remove registros duplicados;

na.drop(): remove linhas com valores nulos (null).

ğŸ“Œ Por que fazer isso na Bronze?

Reduz complexidade nas camadas Silver e Gold;

Evita erros em joins e mÃ©tricas erradas;

Garante que os dados cheguem limpos para anÃ¡lise.


"Engenharia de dados comeÃ§a na Bronze: quanto melhor a base, mais poderosa serÃ¡ a entrega."
