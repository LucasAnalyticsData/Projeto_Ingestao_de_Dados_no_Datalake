## ğŸ“ Projeto de Engenharia de Dados - Pipeline Bronze â†’ Silver â†’ Gold

### ğŸ‘¨â€ğŸ’¼ Autor: Lucas Sousa Santos Oliveira
Especialista em FinanÃ§as em transiÃ§Ã£o para Engenharia de Dados | PÃ³s-graduaÃ§Ã£o em Big Data e Cloud Computing

---

## ğŸ¯ Objetivo do Projeto
Criar um pipeline de dados robusto, escalÃ¡vel e otimizado usando Databricks e Delta Lake, com foco em boas prÃ¡ticas de ingestÃ£o, processamento e entrega de dados para analytics e decisÃµes de negÃ³cio.

---

## ğŸ§± Arquitetura em Camadas

```mermaid
graph TD
  A[Camada Bronze - Raw Data] --> B[Camada Silver - Dados Tratados]
  B --> C[Camada Gold - Modelo AnalÃ­tico]
  C --> D[Consumo: Power BI / Databricks SQL / API]
```

---

## ğŸ”½ Camada Bronze (IngestÃ£o)

### âœ… ResponsÃ¡vel por:
- Capturar dados brutos de mÃºltiplas fontes (CSV, APIs, arquivos externos).
- Armazenar em Delta Lake mantendo fidelidade com a fonte.

### âœ… Melhorias aplicadas:
- ğŸ“¥ **Auto Loader com trigger(once)** para leitura eficiente e econÃ´mica.
- ğŸ§¹ PrÃ©-tratamento bÃ¡sico: `dropDuplicates`, `na.drop()`
- ğŸ“ Particionamento por data (`partitionBy("data_carga")`).
- ğŸ’¾ Salvamento em formato Delta Lake com schema evolution.

---

## ğŸª„ Camada Silver (TransformaÃ§Ã£o)

### âœ… ResponsÃ¡vel por:
- Normalizar os dados, aplicar consistÃªncia e enriquecer com joins.
- Aplicar lÃ³gicas de negÃ³cio (ex: status, flags, filtros de qualidade).

### ğŸ” TÃ©cnicas usadas:
- Join com dimensÃµes (cliente, produto).
- CriaÃ§Ã£o de colunas de rastreabilidade (`created_at`, `hash_id`).
- ValidaÃ§Ãµes de qualidade (status vÃ¡lidos, tipos consistentes).

---

## ğŸ¥‡ Camada Gold (Modelo AnalÃ­tico)

### âœ… ResponsÃ¡vel por:
- Entregar dados prontos para dashboards, relatÃ³rios e APIs.
- Atender ao modelo dimensional (tabelas fato e dimensÃ£o).

### ğŸ§  Entregas chave:
- Fato Vendas com mÃ©tricas normalizadas
- DimensÃµes limpas e auditÃ¡veis
- Views para consumo por BI

---

## ğŸš€ OtimizaÃ§Ãµes Spark Aplicadas

| TÃ©cnica                       | BenefÃ­cio                                        
|------------------------------|-------------------------------------------------|
| Auto Loader                  | Leitura incremental e eficiente                 |
| Trigger Once / AvailableNow  | Economia de cluster em batch                    |
| PartitionBy                  | ReduÃ§Ã£o de I/O e ganho de leitura               |
| Checkpoint Location          | TolerÃ¢ncia a falhas em stream                   |
| Round / cast tipos           | ReduÃ§Ã£o de processamento no Gold                |
| Delta Format                 | ACID, time travel e performance                 |

---

## ğŸ“Š Monitoramento e Qualidade

- Delta Live Tables com **Expectations**
- Alertas com Databricks Jobs e notificaÃ§Ãµes
- Logs de execuÃ§Ã£o persistidos em Delta

---

## ğŸ“ˆ EvoluÃ§Ã£o para Projeto AvanÃ§ado

### Etapas sugeridas:

1. **Streaming com Auto Loader** e monitoramento contÃ­nuo.
2. **Data Quality em tempo real** com Delta Live Tables.
3. **IngestÃ£o de mÃºltiplas fontes** (API, Webhooks, bancos relacionais).
4. **GovernanÃ§a com Unity Catalog**.
5. **Pipelines agendados com Databricks Workflows**.
6. **Views de Consumo em Databricks SQL + Power BI**.
7. **VersÃµes automatizadas com GitHub + CI/CD**.

---

## ğŸ§  ConclusÃ£o
Este projeto evolui de uma ingestÃ£o simples de arquivos CSV para uma arquitetura escalÃ¡vel, segura e de alto valor analÃ­tico. Com tÃ©cnicas modernas de engenharia de dados aplicadas, estÃ¡ pronto para suportar decisÃµes estratÃ©gicas em ambientes corporativos.

> "Engenharia de Dados Ã© mais do que mover bits â€” Ã© sobre criar pontes entre dados brutos e decisÃµes inteligentes."

---


